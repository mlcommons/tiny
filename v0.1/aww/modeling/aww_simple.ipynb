{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pydub\n",
    "#apt-get install ffmpeg libavcodec-extra\n",
    "#pip install ffprobe-python\n",
    "#pip install tensorflow_datasets -U\n",
    "#pip install -q tensorflow-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.6/dist-packages')\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import wave\n",
    "import os\n",
    "#import tensorflow_io as tfio\n",
    "from tensorflow.python.platform import gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset speech_commands/0.0.2 (download: 2.37 GiB, generated: 8.17 GiB, total: 10.53 GiB) to /home/jeremy/tensorflow_datasets/speech_commands/0.0.2...\u001b[0m\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# No total? Show info style bar with no progress tqdm status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIProgress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'IProgress' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fa1f3fa809b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"speech_commands\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprefetch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/jeremy_tdk/lib/python3.6/site-packages/tensorflow_datasets/core/api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[0;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/jeremy_tdk/lib/python3.6/site-packages/tensorflow_datasets/core/registered.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_and_prepare_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m     \u001b[0mdbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mas_dataset_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/jeremy_tdk/lib/python3.6/site-packages/tensorflow_datasets/core/api_utils.py\u001b[0m in \u001b[0;36mdisallow_positional_args_dec\u001b[0;34m(fn, instance, args, kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0m_check_no_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0m_check_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdisallow_positional_args_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/jeremy_tdk/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, download_dir, download_config)\u001b[0m\n\u001b[1;32m    374\u001b[0m           self._download_and_prepare(\n\u001b[1;32m    375\u001b[0m               \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m               download_config=download_config)\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m           \u001b[0;31m# NOTE: If modifying the lines below to put additional information in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/jeremy_tdk/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     super(GeneratorBasedBuilder, self)._download_and_prepare(\n\u001b[1;32m   1018\u001b[0m         \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m         \u001b[0mmax_examples_per_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_examples_per_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/jeremy_tdk/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    937\u001b[0m         prepare_split_kwargs)\n\u001b[1;32m    938\u001b[0m     for split_generator in self._split_generators(\n\u001b[0;32m--> 939\u001b[0;31m         dl_manager, **split_generators_kwargs):\n\u001b[0m\u001b[1;32m    940\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/jeremy_tdk/lib/python3.6/site-packages/tensorflow_datasets/audio/speech_commands.py\u001b[0m in \u001b[0;36m_split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     dl_path, dl_test_path = dl_manager.download(\n\u001b[0;32m---> 95\u001b[0;31m         [_DOWNLOAD_PATH, _TEST_DOWNLOAD_PATH_])\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     train_paths, validation_paths = self._split_archive(\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/jeremy_tdk/lib/python3.6/site-packages/tensorflow_datasets/core/download/download_manager.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \"\"\"\n\u001b[1;32m    544\u001b[0m     \u001b[0;31m# Add progress bar to follow the download state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_downloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_map_promise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl_or_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/jeremy_tdk/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/jeremy_tdk/lib/python3.6/site-packages/tensorflow_datasets/core/download/downloader.py\u001b[0m in \u001b[0;36mtqdm\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;34m\"\"\"Add a progression bar for the current download.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0masync_tqdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0masync_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Dl Completed...'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' url'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar_url\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0masync_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Dl Size...'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' MiB'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar_dl_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pbar_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpbar_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/jeremy_tdk/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/jeremy_tdk/lib/python3.6/site-packages/tensorflow_datasets/core/utils/tqdm_utils.py\u001b[0m in \u001b[0;36m_async_tqdm\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAsync\u001b[0m \u001b[0mpbar\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mshared\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mtqdm_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TqdmPbarAsync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         self.container = self.status_printer(\n\u001b[0;32m--> 209\u001b[0;31m             self.fp, total, self.desc, self.ncols)\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# #187 #451 #558\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise ImportError(\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0;34m\"FloatProgress not found. Please update jupyter and ipywidgets.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0;34m\" See https://ipywidgets.readthedocs.io/en/stable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \"/user_install.html\")\n",
      "\u001b[0;31mImportError\u001b[0m: FloatProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "sys.path.append('/usr/local/lib/python3.6/dist-packages')\n",
    "import ffprobe\n",
    "download=True\n",
    "name=\"speech_commands\"\n",
    "ds = tfds.load(name,download=download,shuffle_files=True)\n",
    "num_parallel_calls = 4\n",
    "prefetch_size = 2\n",
    "resize_shape = False\n",
    "\n",
    "dct_coefficient_count=10 \n",
    "window_size_ms=40 \n",
    "window_stride_ms=20\n",
    "clip_duration_ms=1000 #expected duration in ms\n",
    "sample_rate=16000\n",
    "label_count=12\n",
    "background_frequency = 0.8\n",
    "background_volume_range_=0.1\n",
    "\n",
    "def prepare_model_settings(label_count, sample_rate, clip_duration_ms,\n",
    "                               window_size_ms, window_stride_ms,\n",
    "                               dct_coefficient_count,background_frequency):\n",
    "      \"\"\"Calculates common settings needed for all models.\n",
    "      Args:\n",
    "        label_count: How many classes are to be recognized.\n",
    "        sample_rate: Number of audio samples per second.\n",
    "        clip_duration_ms: Length of each audio clip to be analyzed.\n",
    "        window_size_ms: Duration of frequency analysis window.\n",
    "        window_stride_ms: How far to move in time between frequency windows.\n",
    "        dct_coefficient_count: Number of frequency bins to use for analysis.\n",
    "      Returns:\n",
    "        Dictionary containing common settings.\n",
    "      \"\"\"\n",
    "      desired_samples = int(sample_rate * clip_duration_ms / 1000)\n",
    "      window_size_samples = int(sample_rate * window_size_ms / 1000)\n",
    "      window_stride_samples = int(sample_rate * window_stride_ms / 1000)\n",
    "      length_minus_window = (desired_samples - window_size_samples)\n",
    "      if length_minus_window < 0:\n",
    "        spectrogram_length = 0\n",
    "      else:\n",
    "        spectrogram_length = 1 + int(length_minus_window / window_stride_samples)\n",
    "      fingerprint_size = dct_coefficient_count * spectrogram_length\n",
    "      return {\n",
    "          'desired_samples': desired_samples,\n",
    "          'window_size_samples': window_size_samples,\n",
    "          'window_stride_samples': window_stride_samples,\n",
    "          'spectrogram_length': spectrogram_length,\n",
    "          'dct_coefficient_count': dct_coefficient_count,\n",
    "          'fingerprint_size': fingerprint_size,\n",
    "          'label_count': label_count,\n",
    "          'sample_rate': sample_rate,\n",
    "          'background_frequency': 0.8,\n",
    "          'background_volume_range_': 0.1\n",
    "      }\n",
    "    \n",
    "def get_preprocess_audio_func(model_settings,is_training=False,background_data = []):\n",
    "    def prepare_processing_graph(next_element):\n",
    "        \"\"\"Builds a TensorFlow graph to apply the input distortions.\n",
    "        Creates a graph that loads a WAVE file, decodes it, scales the volume,\n",
    "        shifts it in time, adds in background noise, calculates a spectrogram, and\n",
    "        then builds an MFCC fingerprint from that.\n",
    "        This must be called with an active TensorFlow session running, and it\n",
    "        creates multiple placeholder inputs, and one output:\n",
    "          - wav_filename_placeholder_: Filename of the WAV to load.\n",
    "          - foreground_volume_placeholder_: How loud the main clip should be.\n",
    "          - time_shift_padding_placeholder_: Where to pad the clip.\n",
    "          - time_shift_offset_placeholder_: How much to move the clip in time.\n",
    "          - background_data_placeholder_: PCM sample data for background noise.\n",
    "          - background_volume_placeholder_: Loudness of mixed-in background.\n",
    "          - mfcc_: Output 2D fingerprint of processed audio.\n",
    "        Args:\n",
    "          model_settings: Information about the current model being trained.\n",
    "        \"\"\"\n",
    "        desired_samples = model_settings['desired_samples']\n",
    "        background_frequency = model_settings['background_frequency']\n",
    "        background_volume_range_= model_settings['background_volume_range_']\n",
    "        wav_decoder = tf.cast(next_element['audio'], tf.float32)\n",
    "        wav_decoder = wav_decoder/tf.reduce_max(wav_decoder)\n",
    "        wav_decoder = tf.pad(wav_decoder,[[0,desired_samples-tf.shape(wav_decoder)[-1]]]) #Previously, decode_wav was used with desired_samples as the length of array. The default option of this function was to pad zeros if the desired samples are not found\n",
    "        # Allow the audio sample's volume to be adjusted.\n",
    "        foreground_volume_placeholder_ = tf.constant(1,dtype=tf.float32)\n",
    "        \n",
    "        scaled_foreground = tf.multiply(wav_decoder,\n",
    "                                        foreground_volume_placeholder_)\n",
    "        # Shift the sample's start position, and pad any gaps with zeros.\n",
    "        time_shift_padding_placeholder_ = tf.constant([[2,2]], tf.int32)\n",
    "        time_shift_offset_placeholder_ = tf.constant([2],tf.int32)\n",
    "        scaled_foreground.shape\n",
    "        padded_foreground = tf.pad(scaled_foreground, time_shift_padding_placeholder_, mode='CONSTANT')\n",
    "        sliced_foreground = tf.slice(padded_foreground, time_shift_offset_placeholder_, [desired_samples])\n",
    "        \n",
    "    \n",
    "        if is_training and background_data != []:\n",
    "            background_volume_range = tf.constant(background_volume_range_,dtype=tf.float32)\n",
    "            background_index = np.random.randint(len(background_data))\n",
    "            background_samples = background_data[background_index]\n",
    "            background_offset = np.random.randint(0, len(background_samples) - desired_samples)\n",
    "            background_clipped = background_samples[background_offset:(background_offset + desired_samples)]\n",
    "            background_clipped = tf.squeeze(background_clipped)\n",
    "            #print(background_clipped)\n",
    "            #background_reshaped = background_clipped.reshape([desired_samples, 1])\n",
    "            background_reshaped = tf.pad(background_clipped,[[0,desired_samples-tf.shape(wav_decoder)[-1]]])\n",
    "            background_reshaped = tf.cast(background_reshaped, tf.float32)\n",
    "            if np.random.uniform(0, 1) < background_frequency:\n",
    "                background_volume = np.random.uniform(0, background_volume_range_)\n",
    "            else:\n",
    "                background_volume = 0\n",
    "            #background_data_placeholder_ = tf.placeholder(tf.float32, [desired_samples, 1])\n",
    "            background_volume_placeholder_ = tf.constant(background_volume,dtype=tf.float32)\n",
    "            background_data_placeholder_ = background_reshaped\n",
    "            background_mul = tf.multiply(background_data_placeholder_,\n",
    "                                 background_volume_placeholder_)\n",
    "            background_add = tf.add(background_mul, sliced_foreground)\n",
    "            sliced_foreground = tf.clip_by_value(background_add, -1.0, 1.0)\n",
    "        \n",
    "        if True:\n",
    "            stfts = tf.signal.stft(sliced_foreground, frame_length=model_settings['window_size_samples'], \n",
    "                                   frame_step=model_settings['window_stride_samples'], fft_length=None,\n",
    "                                   window_fn=tf.signal.hann_window\n",
    "                                   )\n",
    "            spectrograms = tf.abs(stfts)\n",
    "            num_spectrogram_bins = stfts.shape[-1]\n",
    "            #default values used by contrib_audio.mfcc as shown here https://kite.com/python/docs/tensorflow.contrib.slim.rev_block_lib.contrib_framework_ops.audio_ops.mfcc\n",
    "            lower_edge_hertz, upper_edge_hertz, num_mel_bins = 20.0, 4000.0, 40 \n",
    "            linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix( num_mel_bins, num_spectrogram_bins, model_settings['sample_rate'],\n",
    "                                                                                lower_edge_hertz, upper_edge_hertz)\n",
    "            mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n",
    "            mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(linear_to_mel_weight_matrix.shape[-1:]))\n",
    "            # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n",
    "            log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n",
    "            # Compute MFCCs from log_mel_spectrograms and take the first 13.\n",
    "            mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)[..., :model_settings['dct_coefficient_count']]\n",
    "            mfccs = tf.reshape(mfccs,[model_settings['spectrogram_length'], model_settings['dct_coefficient_count'], 1])\n",
    "            next_element['audio'] = mfccs\n",
    "            next_element['label'] = tf.one_hot(next_element['label'],12)\n",
    "        #next_element['audio'] = sliced_foreground\n",
    "        return next_element\n",
    "    \n",
    "    return prepare_processing_graph\n",
    "\n",
    "model_settings = prepare_model_settings(label_count, sample_rate, clip_duration_ms,\n",
    "                               window_size_ms, window_stride_ms,\n",
    "                               dct_coefficient_count,background_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_path='/home/urmtha01/MountedLogs/BG_NOISE/'\n",
    "BACKGROUND_NOISE_DIR_NAME='_background_noise_'\n",
    "def prepare_background_data(bg_path,BACKGROUND_NOISE_DIR_NAME):\n",
    "    \"\"\"Searches a folder for background noise audio, and loads it into memory.\n",
    "    It's expected that the background audio samples will be in a subdirectory\n",
    "    named '_background_noise_' inside the 'data_dir' folder, as .wavs that match\n",
    "    the sample rate of the training data, but can be much longer in duration.\n",
    "    If the '_background_noise_' folder doesn't exist at all, this isn't an\n",
    "    error, it's just taken to mean that no background noise augmentation should\n",
    "    be used. If the folder does exist, but it's empty, that's treated as an\n",
    "    error.\n",
    "    Returns:\n",
    "      List of raw PCM-encoded audio samples of background noise.\n",
    "    Raises:\n",
    "      Exception: If files aren't found in the folder.\n",
    "    \"\"\"\n",
    "    background_data = []\n",
    "    background_dir = os.path.join(bg_path, BACKGROUND_NOISE_DIR_NAME)\n",
    "    if not os.path.exists(background_dir):\n",
    "      return background_data\n",
    "    #with tf.Session(graph=tf.Graph()) as sess:\n",
    "    #    wav_filename_placeholder = tf.placeholder(tf.string, [])\n",
    "    #    wav_loader = io_ops.read_file(wav_filename_placeholder)\n",
    "    #    wav_decoder = contrib_audio.decode_wav(wav_loader, desired_channels=1)\n",
    "    search_path = os.path.join(bg_path, BACKGROUND_NOISE_DIR_NAME,'*.wav')\n",
    "    #for wav_path in gfile.Glob(search_path):\n",
    "    #    wav_data = sess.run(wav_decoder, feed_dict={wav_filename_placeholder: wav_path}).audio.flatten()\n",
    "    #    self.background_data.append(wav_data)\n",
    "    for wav_path in gfile.Glob(search_path):\n",
    "        #audio = tfio.audio.AudioIOTensor(wav_path)\n",
    "        raw_audio = tf.io.read_file(wav_path)\n",
    "        audio = tf.audio.decode_wav(raw_audio)\n",
    "        background_data.append(audio[0])\n",
    "    if not background_data:\n",
    "        raise Exception('No background wav files were found in ' + search_path)\n",
    "    return background_data\n",
    "background_data = prepare_background_data(bg_path,BACKGROUND_NOISE_DIR_NAME)\n",
    "#is_training=True\n",
    "#background_volume_range_=0.1\n",
    "#print(tf.reduce_max(background_data[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train'] = ds['train'].map(get_preprocess_audio_func(model_settings,is_training=True,background_data=background_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = ds['train'].__iter__()\n",
    "\n",
    "for i in range(5):\n",
    "    next_element = iterator.get_next()\n",
    "    tf.print(next_element['audio'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
